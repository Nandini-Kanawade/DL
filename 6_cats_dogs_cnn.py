# -*- coding: utf-8 -*-
"""Copy of DL_Exp_catdog_4B

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ABhomU_1rwAkhYknnduEuOwK5CgvkhNk

**Image classification on cat dog dataset using CNN**
"""

!wget --no-check-certificate \
    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \
    -O /tmp/cats_and_dogs_filtered.zip

import os
import zipfile

local_zip = '/tmp/cats_and_dogs_filtered.zip' # path to the zip file
zip_ref = zipfile.ZipFile(local_zip, 'r') #zipfile.ZipFile function is used to create a ZipFile object (zip_ref) that opens the zip file in read mode ('r').
zip_ref.extractall('/tmp') #extracts and tmp is the directory
zip_ref.close() # closes the ZipFile object to free up system resources.

# oraganizing the datasets
#defining the database
base_dir = '/tmp/cats_and_dogs_filtered'
train_dir = os.path.join(base_dir, 'train')
validation_dir = os.path.join(base_dir, 'validation') #func joins one or more paths
#traning and validation sets for evaluating the datasets
#validatoin: to evaluate the performance during the training and tune hyper param
# Directory with our training cat pictures
train_cats_dir = os.path.join(train_dir, 'cats') #traning sets beacuse to adjust the parameter(weights) and optomization algo like gradient dsecent

# Directory with our training dog pictures
train_dogs_dir = os.path.join(train_dir, 'dogs')

# Directory with our validation cat pictures
validation_cats_dir = os.path.join(validation_dir, 'cats')

# Directory with our validation dog pictures
validation_dogs_dir = os.path.join(validation_dir, 'dogs')

""" lists the filenames of the first ten cat and dog images in the training set and prints the total number of images in each category for both training and validation sets."""

train_cat_fnames = os.listdir(train_cats_dir) # returns a list of file/imgs within that directory
train_cat_fnames.sort() #to provide consistency sorted based on lexicographic order for strings
print(train_cat_fnames[:10])

train_dog_fnames = os.listdir(train_dogs_dir)
train_dog_fnames.sort()
print(train_dog_fnames[:10])

"""Let's find out the total number of cat and dog images in the `train` and `validation` directories:"""

print('total training cat images:', len(os.listdir(train_cats_dir)))
print('total training dog images:', len(os.listdir(train_dogs_dir)))
print('total validation cat images:', len(os.listdir(validation_cats_dir)))
print('total validation dog images:', len(os.listdir(validation_dogs_dir)))

import matplotlib.pyplot as plt
import matplotlib.image as mpimg # for loading, displaying, and manipulating image data.

# Parameters for our graph; we'll output images in a 4x4 configuration
nrows = 4
ncols = 4  #visualisation grid

# Index for iterating over images

"""Now, display a batch of 8 cat and 8 dog pictures."""

# Set up matplotlib fig, and size it to fit 4x4 pics
fig = plt.gcf()
fig.set_size_inches(ncols * 4, nrows * 4)
pic_index=0
pic_index += 8
next_cat_pix = [os.path.join(train_cats_dir, fname)
                for fname in train_cat_fnames[pic_index-8:pic_index]]
next_dog_pix = [os.path.join(train_dogs_dir, fname)
                for fname in train_dog_fnames[pic_index-8:pic_index]]

for i, img_path in enumerate(next_cat_pix+next_dog_pix):
  # Set up subplot; subplot indices start at 1
  sp = plt.subplot(nrows, ncols, i + 1)
  sp.axis('Off') # Don't show axes (or gridlines)

  img = mpimg.imread(img_path)
  plt.imshow(img)

plt.show()

"""Building CNN"""

from tensorflow.keras import layers
from tensorflow.keras import Model

# Our input feature map is 150x150x3: 150x150 for the image pixels, and 3 for
# the three color channels: R, G, and B
img_input = layers.Input(shape=(150, 150, 3))

# First convolution extracts 16 filters that are 3x3
# Convolution is followed by max-pooling layer with a 2x2 window
x = layers.Conv2D(16, 3, activation='relu')(img_input)
x = layers.MaxPooling2D(2)(x)

# Second convolution extracts 32 filters that are 3x3
# Convolution is followed by max-pooling layer with a 2x2 window
x = layers.Conv2D(32, 3, activation='relu')(x)
x = layers.MaxPooling2D(2)(x)

# Third convolution extracts 64 filters that are 3x3
# Convolution is followed by max-pooling layer with a 2x2 window
x = layers.Conv2D(64, 3, activation='relu')(x)
x = layers.MaxPooling2D(2)(x)

# Flatten feature map to a 1-dim tensor so we can add fully connected layers
x = layers.Flatten()(x)

# Create a fully connected layer with ReLU activation and 512 hidden units
x = layers.Dense(512, activation='relu')(x)

# Create output layer with a single node and sigmoid activation
output = layers.Dense(1, activation='sigmoid')(x)

# Create model:
# input = input feature map
# output = input feature map + stacked convolution/maxpooling layers + fully
# connected layer + sigmoid output layer
model = Model(img_input, output)

"""Let's summarize the model architecture:"""

model.summary()
#-2 beacuse 3x3 kernel
# 448 = 3x3 x3 x16 + 16
# 4680 = 3x3 x16 x32 + 32
# 18496 = 3x3 x32 x 64 + 64

""" `binary_crossentropy` loss,  final activation is a sigmoid.


"""

from tensorflow.keras.optimizers import RMSprop

model.compile(loss='binary_crossentropy',
              optimizer=RMSprop(learning_rate=0.001),
              metrics=['acc'])

"""### Data Preprocessing


"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# All images will be rescaled by 1./255
train_datagen = ImageDataGenerator(rescale=1./255)
val_datagen = ImageDataGenerator(rescale=1./255)

# Flow training images in batches of 20 using train_datagen generator
train_generator = train_datagen.flow_from_directory(
        train_dir,  # This is the source directory for training images
        target_size=(150, 150),  # All images will be resized to 150x150
        batch_size=20,
        # Since we use binary_crossentropy loss, we need binary labels
        class_mode='binary')

# Flow validation images in batches of 20 using val_datagen generator
validation_generator = val_datagen.flow_from_directory(
        validation_dir,
        target_size=(150, 150),
        batch_size=20,
        class_mode='binary')

"""### Training
Let's train on all 2,000 images available, for 5 epochs, and validate on all 1,000 validation images. (This may take a few minutes to run.)
"""

history = model.fit(
      train_generator,
      steps_per_epoch=100,  # 2000 images = batch_size * steps
      epochs=10,


      validation_data=validation_generator,
      validation_steps=50,  # 1000 images = batch_size * steps
      verbose=2)

"""### Evaluating Accuracy and Loss for the Model


"""

# Retrieve a list of accuracy results on training and validation data
# sets for each training epoch
acc = history.history['acc']
val_acc = history.history['val_acc']

# Retrieve a list of list results on training and validation data
# sets for each training epoch
loss = history.history['loss']
val_loss = history.history['val_loss']

# Get number of epochs
epochs = range(len(acc))

# Plot training and validation accuracy per epoch
plt.plot(epochs, acc)
plt.plot(epochs, val_acc)
plt.title('Training and validation accuracy')

plt.figure()

# Plot training and validation loss per epoch
plt.plot(epochs, loss)
plt.plot(epochs, val_loss)
plt.title('Training and validation loss')

import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing import image

# Preprocess the images (e.g., resize and rescale)
def preprocess_image(img_path):
    img = image.load_img(img_path, target_size=(150, 150))
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array /= 255.0  # Rescale pixel values
    return img_array

# Load the trained model
model = model  # Load your trained model here

temp = os.listdir(validation_cats_dir)
temp.sort()
print(temp[:10])

# Path to the images you want to predict
image_paths = ['/tmp/cats_and_dogs_filtered/validation/cats/cat.2000.jpg', '/tmp/cats_and_dogs_filtered/validation/cats/cat.2001.jpg']  # List of image file paths

print(image_paths)

# Predict each image
for img_path in image_paths:
    # Preprocess the image
    img_array = preprocess_image(img_path)

    # Perform prediction
    prediction = model.predict(img_array)

    # Display the original image
    img = image.load_img(img_path)
    plt.imshow(img)
    plt.axis('off')
    plt.show()

    # Display prediction results (modify as needed based on your model's output)
    if prediction[0] > 0.5:
        print("Prediction: Dog")
    else:
        print("Prediction: Cat")

